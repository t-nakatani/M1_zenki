{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e35c788",
   "metadata": {},
   "source": [
    "# TF-IDF(Term Frequency - Inverse Document Frequency)\n",
    "\n",
    "$$TF\\_IDF = TF * IDF$$\n",
    "<br>\n",
    "$$tf(word_i, doc_j) = \\frac{num(word_i\\_in\\_doc_j)}{num(all\\_words\\_in\\_all\\_docs)}$$\n",
    "<br>\n",
    "$$idf(word_i) = log(\\frac{num(all\\_docs)}{num(docs\\_which\\_include\\_word_i)})$$\n",
    "\n",
    "tf-idf(i, j): 文書jにおける単語iの重要性  \n",
    "tf(i, j): 全文書の全単語に対する，ある文書jにおける，単語iの占める割合  \n",
    "idf(i): 全文書のうち，単語iを含む文書の割合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4566a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import math\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5169bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(word_dict, bow):\n",
    "    tf_dict = {}\n",
    "    bow_cnt = len(bow)\n",
    "    for word, cnt in word_dict.items():\n",
    "        tf_dict[word] = cnt / float(bow_cnt)\n",
    "    return tf_dict\n",
    "\n",
    "def computeIDF(doc_dict):\n",
    "    N = len(doc_dict)\n",
    "    idf_dict = dict(zip(doc_dict[0].keys(), [0]*len(doc_dict[0])) )\n",
    "    for doc in doc_dict:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idf_dict[word] += 1\n",
    "    \n",
    "    for word, val in idf_dict.items():\n",
    "        idf_dict[word] = math.log(N / float(val))\n",
    "    return idf_dict\n",
    "\n",
    "def computeTFIDF(tf_bow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tf_bow.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "251bdc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2TFIDF(docA, docB):\n",
    "    # Bag of Words\n",
    "    bowA = docA.split(' ')\n",
    "    bowB = docB.split(' ')\n",
    "    unique = set(bowA + bowB)\n",
    "    # print(unique)\n",
    "\n",
    "    num_wordsA = dict(zip(unique, [0]*len(unique)))\n",
    "    for word in bowA:\n",
    "        num_wordsA[word] += 1\n",
    "    num_wordsB = dict(zip(unique, [0]*len(unique)))\n",
    "    for word in bowB:\n",
    "        num_wordsB[word] += 1\n",
    "\n",
    "#     stop_words = stopwords.words('english')\n",
    "\n",
    "    tfA = computeTF(num_wordsA, bowA)\n",
    "    tfB = computeTF(num_wordsB, bowB)\n",
    "    # tfA, tfB\n",
    "\n",
    "    doc_dict = [num_wordsA, num_wordsB]\n",
    "    idfs = computeIDF(doc_dict)\n",
    "    # idfs\n",
    "\n",
    "    tfidfA = computeTFIDF(tfA, idfs)\n",
    "    tfidfB = computeTFIDF(tfB, idfs)\n",
    "    df = pd.DataFrame([tfidfA, tfidfB])\n",
    "\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd82603",
   "metadata": {},
   "source": [
    "# 参考\n",
    "[TF IDF | TFIDF Python Example](https://towardsdatascience.com/natural-language-processing-feature-engineering-using-tf-idf-e8b9d00e7e76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ddc05c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "space line is detected !\n",
      "\n",
      "num lines in document == 3\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "LI0630 = '../LI22/20220630'\n",
    "with open(os.path.join(LI0630, \"data_org.txt\")) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if line.isspace():\n",
    "            print('space line is detected !\\n')\n",
    "            continue\n",
    "        # strip(): デフォルトでは両端の連続する空白文字が取り除かれる。\n",
    "        #改行\\nや全角スペース\\u3000やタブ\\tなどが空白文字とみなされ削除される。\n",
    "        line=line.strip() \n",
    "        result.append(line)\n",
    "        \n",
    "with open(os.path.join(LI0630, \"result.txt\"),\"w\") as f:\n",
    "    for line in result:\n",
    "        f.write(line+\"\\n\")\n",
    "print(f'num lines in document == {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8e0f778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['child',\n",
       "  'would',\n",
       "  'not',\n",
       "  'be',\n",
       "  'wearing',\n",
       "  'shorts',\n",
       "  'in',\n",
       "  'below',\n",
       "  'freezing',\n",
       "  'weather'],\n",
       " 10220)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "bag_of_words[-10:], len(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a044afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: the 0.07348336594911938\n",
      "1: and 0.05342465753424658\n",
      "2: of 0.04442270058708415\n",
      "3: long 0.043835616438356165\n",
      "4: mike 0.0213307240704501\n"
     ]
    }
   ],
   "source": [
    "def computeTF(word_dict, bow):\n",
    "    tf_dict = {}\n",
    "    bow_cnt = len(bow)\n",
    "    for word, cnt in word_dict.items():\n",
    "        tf_dict[word] = cnt / float(bow_cnt)\n",
    "    return tf_dict\n",
    "\n",
    "path = '/Users/nakatani/Desktop/22前期/言語情報学/LI22/20220630/data1.txt'\n",
    "with open(path) as f:\n",
    "    doc = f.read()\n",
    "bag_of_words = ([word.lower() for word in doc.split()])\n",
    "unique = set(bag_of_words)\n",
    "num_words = dict(zip(unique, [0]*len(unique)))\n",
    "for word in bag_of_words:\n",
    "    num_words[word] += 1\n",
    "\n",
    "tf = computeTF(num_words, bag_of_words)\n",
    "top5 = sorted([[value, key] for key, value in tf.items()], reverse=True)[:5]\n",
    "for i, value_key in enumerate(top5):\n",
    "    value, key = value_key\n",
    "    print(f'{i}: {key} {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e57a6c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[751, 'the'], [546, 'and'], [454, 'of'], [448, 'long'], [218, 'mike']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc0edd90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@@12747081 @1347081/ <h> Plural Possessives : Why You Put an Apostrophe After the S <p> Its common for people to wonder , \" What does it mean to put an apostrophe after an S ? \" It can get a bit confusing . To get it right , you need to understand what a possessive is . <p> Possessives are used to show ownership ; to show that something belongs to someone . \" The presidents official airplane \" is one example . The airplane belongs to the president , of course . But there is only one president ; after all , you do n\\'t  have two presidents of the same country . So , this is a singular possessive made by adding an apostrophe and an \" s . \" <p> But with a phrase such as \" the thieves jewels , \" you have a plural noun : thieves . Most of the time , a plural noun will be formed by adding \" s \" to it . In this case , you also change the spelling but do n\\'t  worry about that now . The main @ @ @ @ @ @ @ @ @ @ . \" Houses , cats , clouds , essays , rainbows : these are all plural nouns . <p> As you can see , the fact that the thieves ( illegally ) possess the jewels is shown simply by adding an apostrophe after the noun and after the letter \" s . \" They may not possess these valuables for long unless they \\'re clever and know how to escape the police , but they do for now . And that \\'s how you form a plural possessive . <p> To recap , usually if the noun is singular , the apostrophe will go before the s , but if the noun happens to be plural , the apostrophe will go after the s . <h> Plural Possessive Examples <p> The Simpsons spaceship ( the spaceship belongs to the Simpson family ; you make the family name plural to show that you \\'re referring to all of the family members ) <p> The dogs tails ( the tails belong to the dogs ) <p> The lakes water ( the water belongs to the lakes ) <p> You have to be careful with the @ @ @ @ @ @ @ @ @ @ one lake , you must write : \" the lakes water . \" In this case , that \\'s a singular possessive . <p> An even bigger problem these days is when people write sentences such as this : \" None of the monkeys looked happy in the zoo . \" There is no reason to use an apostrophe to make a possessive here . The sentence is only talking about monkeys in the plural . They do not own anything ! However , this is a commonly repeated mistake across the Internet . <p> Sometimes its hard to see how the possessive works . \" You owe me three months pay immediately ! \" Oh , I do ? Let me check my wallet . And my grammar guide . Why is there an apostrophe after \" months ? \" Because the pay is equal to three months of work . In a sense , the pay belongs to those three months . Its like saying \" three months of pay . \" If you can use the word \" of \" in the sentence , then you probably need @ @ @ @ @ @ @ @ @ @ you think you \\'ve learned all the rules , you \\'re in for a surprise . There \\'s another type of plural possessive : the irregular plural possessive . The childrens work was so poorly done that the teacher fainted and had to go to the hospital . Okay , this might not really happen , but I used to be a teacher , and sometimes I felt like fainting ! <p> The main point is this . \" Children \" is already plural . You can not add \" s \" to the word itself to make it plural . So when you want to show possession , you put the apostrophe first , then the \" s . \" Here are some more examples . <p> The womens babies ( \" women \" is the plural form of \" woman \" ) <p> The firemens trucks ( \" firemen \" is the plural of \" fireman \" ) <p> The dices roll ( \" dice \" always means there is more than one ) <p> These look like singular possessives , but they are n\\'t  . <h> Compound Plural Possessives <p> @ @ @ @ @ @ @ @ @ @ plural possessives , but there \\'s one more rule you need to know . It deals with compound plural possessives . For example , \" Sam and Dave \" is a compound . There are two parts . So which of the following is correct ? <p> Sam and Daves song was number one for six months . <p> Sams and Daves song was number one for six months . <p> The correct one is the first . Why ? Because Sam and Dave made or performed the song together . It belongs to both of them . Only one possessive needs to be given . But you need to be careful . <p> Lucys and Ginas cars are the fastest on my street . <p> Micks and Rods views on equal rights are impressive . <p> In these two examples , you need two possessives , one for each proper noun . Lucy and Gina both have different cars . Mick and Rod have separate views . However , what if Lucy and Gina were mother and daughter , and both of them had the same cars ? Then you @ @ @ @ @ @ @ @ @ @ cars are the fastest on my street . \" <p> With compound plural possessives , its important to remember you have to think a little and decide whether you are talking about two separate people or things , or a single unit with two parts . <h> 4 comments <p> Hey , my name is Heiko . I came here because I did n\\'t  know what plural possessive meant when reading it in my grammar book . Its good that there is a clear explanation like this to help people like me . Thank you ! <p> This has always been quite confusing for me . Especially when the word already ends in an \" s \" I never know what to do with it . It even gets worse when words and in two \" ss \" I think that there should be a better way to indicate possessive than with an apostrophe since that \\'s used for conjunctions .'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6cff84cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:  @@12747081\n",
      "2:  @1347081/\n",
      "1:  <h>\n",
      ":\n",
      "1:  <p>\n",
      ",\n",
      "\"\n",
      "?\n",
      "\"\n",
      ".\n",
      ",\n",
      ".\n",
      "1:  <p>\n",
      ";\n",
      ".\n",
      "\"\n",
      "\"\n",
      ".\n",
      ",\n",
      ".\n",
      ";\n",
      ",\n",
      "\n",
      ".\n",
      ",\n",
      "\"\n",
      ".\n",
      "\"\n",
      "1:  <p>\n",
      "\"\n",
      ",\n",
      "\"\n",
      ":\n",
      ".\n",
      ",\n",
      "\"\n",
      "\"\n",
      ".\n",
      ",\n",
      "\n",
      ".\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      ".\n",
      "\"\n",
      ",\n",
      ",\n",
      ",\n",
      ",\n",
      ":\n",
      ".\n",
      "1:  <p>\n",
      ",\n",
      "(\n",
      ")\n",
      "\"\n",
      ".\n",
      "\"\n",
      "'re\n",
      ",\n",
      ".\n",
      "3:  's\n",
      ".\n",
      "1:  <p>\n",
      ",\n",
      ",\n",
      ",\n",
      ",\n",
      ".\n",
      "1:  <h>\n",
      "1:  <p>\n",
      "(\n",
      ";\n",
      "'re\n",
      ")\n",
      "1:  <p>\n",
      "(\n",
      ")\n",
      "1:  <p>\n",
      "(\n",
      ")\n",
      "1:  <p>\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      ",\n",
      ":\n",
      "\"\n",
      ".\n",
      "\"\n",
      ",\n",
      "3:  's\n",
      ".\n",
      "1:  <p>\n",
      ":\n",
      "\"\n",
      ".\n",
      "\"\n",
      ".\n",
      ".\n",
      "!\n",
      ",\n",
      ".\n",
      "1:  <p>\n",
      ".\n",
      "\"\n",
      "!\n",
      "\"\n",
      ",\n",
      "?\n",
      ".\n",
      ".\n",
      "\"\n",
      "?\n",
      "\"\n",
      ".\n",
      ",\n",
      ".\n",
      "\"\n",
      ".\n",
      "\"\n",
      "\"\n",
      "\"\n",
      ",\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "'ve\n",
      ",\n",
      "'re\n",
      ".\n",
      "3:  's\n",
      ":\n",
      ".\n",
      ".\n",
      ",\n",
      ",\n",
      ",\n",
      "!\n",
      "1:  <p>\n",
      ".\n",
      "\"\n",
      "\"\n",
      ".\n",
      "\"\n",
      "\"\n",
      ".\n",
      ",\n",
      ",\n",
      "\"\n",
      ".\n",
      "\"\n",
      ".\n",
      "1:  <p>\n",
      "(\n",
      "\"\n",
      "\"\n",
      "\"\n",
      "\"\n",
      ")\n",
      "1:  <p>\n",
      "(\n",
      "\"\n",
      "\"\n",
      "\"\n",
      "\"\n",
      ")\n",
      "1:  <p>\n",
      "(\n",
      "\"\n",
      "\"\n",
      ")\n",
      "1:  <p>\n",
      ",\n",
      "\n",
      ".\n",
      "1:  <h>\n",
      "1:  <p>\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      ",\n",
      "3:  's\n",
      ".\n",
      ".\n",
      ",\n",
      "\"\n",
      "\"\n",
      ".\n",
      ".\n",
      "?\n",
      "1:  <p>\n",
      ".\n",
      "1:  <p>\n",
      ".\n",
      "1:  <p>\n",
      ".\n",
      "?\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "1:  <p>\n",
      ".\n",
      "1:  <p>\n",
      ".\n",
      "1:  <p>\n",
      ",\n",
      ",\n",
      ".\n",
      ".\n",
      ".\n",
      ",\n",
      ",\n",
      "?\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      "2:  @\n",
      ".\n",
      "\"\n",
      "1:  <p>\n",
      ",\n",
      ",\n",
      ".\n",
      "1:  <h>\n",
      "4:  4\n",
      "1:  <p>\n",
      ",\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      "!\n",
      "1:  <p>\n",
      ".\n",
      "\"\n",
      "\"\n",
      ".\n",
      "\"\n",
      "\"\n",
      "3:  's\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "result = []\n",
    "words = line.split(' ')\n",
    "for word in words:\n",
    "#     print(word)\n",
    "    if re.match('<.*>', word):\n",
    "        print('1: ', word)\n",
    "        continue\n",
    "    elif re.match('@.*', word):\n",
    "        print('2: ', word)\n",
    "        continue\n",
    "    elif re.match('\\'s', word):\n",
    "        print('3: ', word)\n",
    "        continue\n",
    "    elif re.match('\\d+', word):\n",
    "        print('4: ', word)\n",
    "        continue\n",
    "    elif re.match('[a-zA-Z]+', word):\n",
    "#         print(word)\n",
    "#         result.append(word)\n",
    "        continue\n",
    "    else:\n",
    "        print(word)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9490b9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "space line is detected !\n",
      "\n",
      "/Users/nakatani/Desktop/22前期/言語情報学/LI22/20220630/result.txt\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import re\n",
    "def remove_noise(word_line):\n",
    "    result = []\n",
    "    words = word_line.split(' ')\n",
    "    for word in words:\n",
    "        if re.match('<.*>', word):\n",
    "            continue\n",
    "        elif re.match('@.*', word):\n",
    "            continue\n",
    "        elif re.match('\\'s', word):\n",
    "            continue\n",
    "        elif re.match('\\d+', word):\n",
    "            continue\n",
    "        elif re.match('[a-zA-Z]+', word):\n",
    "            result.append(word)\n",
    "    return ' '.join(result)\n",
    "\n",
    "# args = sys.argv\n",
    "# path = args[1]\n",
    "path = '/Users/nakatani/Desktop/22前期/言語情報学/LI22/20220630/data_org.txt'\n",
    "result = []\n",
    "with open(path) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if line.isspace():\n",
    "            print('space line is detected !\\n')\n",
    "            continue\n",
    "        line=line.strip() \n",
    "        result.append(remove_noise(line))\n",
    "        \n",
    "with open(path.replace('data_org', 'result'),\"w\") as f:\n",
    "    print(path.replace('data_org', 'result'))\n",
    "    for line in result:\n",
    "        f.write(line+\"\\n\")\n",
    "# print(f'num lines in document == {i}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
